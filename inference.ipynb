{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d701ec5f-6ecf-4b9f-bcf1-ca8335fa3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a9e7af-76e5-44ad-912a-5b4e15293b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_batch(\n",
    "\tboxes_a: np.ndarray, boxes_b: np.ndarray\n",
    ") -> np.ndarray:\n",
    "\n",
    "    def box_area(box):\n",
    "        return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "    area_a = box_area(boxes_a.T)\n",
    "    area_b = box_area(boxes_b.T)\n",
    "\n",
    "    top_left = np.maximum(boxes_a[:, None, :2], boxes_b[:, :2])\n",
    "    bottom_right = np.minimum(boxes_a[:, None, 2:], boxes_b[:, 2:])\n",
    "\n",
    "    area_inter = np.prod(\n",
    "    \tnp.clip(bottom_right - top_left, a_min=0, a_max=None), 2)\n",
    "        \n",
    "    return area_inter / (area_a[:, None] + area_b - area_inter)\n",
    "\n",
    "def non_max_suppression(\n",
    "   predictions: np.ndarray, iou_threshold: float = 0.5\n",
    ") -> np.ndarray:\n",
    "    rows, columns = predictions.shape\n",
    "\n",
    "    sort_index = np.flip(predictions[:, 4].argsort())\n",
    "    predictions = predictions[sort_index]\n",
    "\n",
    "    boxes = predictions[:, :4]\n",
    "    categories = predictions[:, 5]\n",
    "    ious = box_iou_batch(boxes, boxes)\n",
    "    ious = ious - np.eye(rows)\n",
    "    # print(ious)\n",
    "\n",
    "    keep = np.ones(rows, dtype=bool)\n",
    "\n",
    "    for index, (iou, category) in enumerate(zip(ious, categories)):\n",
    "        if not keep[index]:\n",
    "            continue\n",
    "\n",
    "        condition = (iou > iou_threshold) & (categories == category)\n",
    "        keep = keep & ~condition\n",
    "\n",
    "    return keep[sort_index.argsort()]\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert bounding box (x, y, w, h) to bounding box (x1, y1, x2, y2)\n",
    "    y = np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9cebbf-5d42-47c1-9f32-9b3b256944ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_session = onnxruntime.SessionOptions()\n",
    "opt_session.enable_mem_pattern = False\n",
    "opt_session.enable_cpu_mem_arena = False\n",
    "opt_session.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "\n",
    "model_path = 'model.onnx'\n",
    "EP_list = ['CPUExecutionProvider']\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(model_path, providers=EP_list)\n",
    "\n",
    "model_inputs = ort_session.get_inputs()\n",
    "input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "input_shape = model_inputs[0].shape\n",
    "\n",
    "model_output = ort_session.get_outputs()\n",
    "output_names = [model_output[i].name for i in range(len(model_output))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "561b958f-0244-470f-8301-a590050901c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "with open('coco.names') as f:\n",
    "    classes = f.read().split('\\n')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        now = time.time()\n",
    "        image_height, image_width = frame.shape[:2]\n",
    "#         Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        input_height, input_width = input_shape[2:]\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        resized = cv2.resize(image_rgb, (input_width, input_height))\n",
    "\n",
    "        # Scale input pixel value to 0 to 1\n",
    "        input_image = resized / 255.0\n",
    "        input_image = input_image.transpose(2,0,1)\n",
    "        input_tensor = input_image[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        outputs = ort_session.run(output_names, {input_names[0]: input_tensor})[0]\n",
    "        predictions = np.squeeze(outputs).T\n",
    "        conf_thresold = 0.6\n",
    "        # Filter out object confidence scores below threshold\n",
    "        scores = np.max(predictions[:, 4:], axis=1)\n",
    "        predictions = predictions[scores > conf_thresold, :]\n",
    "        scores = scores[scores > conf_thresold]\n",
    "        class_ids = np.argmax(predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Get bounding boxes for each object\n",
    "        boxes = predictions[:, :4]\n",
    "\n",
    "        #rescale box\n",
    "        input_shape = np.array([input_width, input_height, input_width, input_height])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([image_width, image_height, image_width, image_height])\n",
    "        boxes = boxes.astype(np.int32)\n",
    "        boxes = xywh2xyxy(boxes)\n",
    "        # print(boxes)\n",
    "        \n",
    "        indices = non_max_suppression(np.concatenate((boxes, np.expand_dims(scores, axis=1), np.expand_dims(class_ids, axis=1)), axis=1), 0.3)\n",
    "        for (bbox, score, label) in zip(boxes[indices], scores[indices], class_ids[indices]):\n",
    "            bbox = bbox.round().astype(np.int32).tolist()\n",
    "            cls = classes[int(label)]\n",
    "            color = (0,255,0)\n",
    "            cv2.rectangle(frame, tuple(bbox[:2]), tuple(bbox[2:]), color, 2)\n",
    "            cv2.putText(frame,\n",
    "                        f'{cls}:{int(score*100)}', (bbox[0], bbox[1] - 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.60, [225, 255, 255],\n",
    "                        thickness=1)\n",
    "        fps = 1 / (time.time() - now)\n",
    "        cv2.putText(frame,\n",
    "                    f'FPS:{round(fps, 2)}', (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, [0,0,255],\n",
    "                    thickness=1)\n",
    "        cv2.imshow(\"video\", frame)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Destroys all the windows created\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
